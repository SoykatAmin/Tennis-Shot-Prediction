{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63441,"sourceType":"datasetVersion","datasetId":39174},{"sourceId":13979377,"sourceType":"datasetVersion","datasetId":8911585}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ca0a0250","cell_type":"markdown","source":"# Tennis Shot Prediction - Repository Demo\n\nThis notebook demonstrates how to use the modular tennis shot prediction repository to analyze and predict tennis shots. The repository provides a clean, well-structured approach to tennis analytics using transformer-based neural networks.\n\n## üéæ What we'll cover:\n1. **Setup and Environment Configuration** - Import modules and configure the environment\n2. **Load and Initialize Dataset** - Use the repository's data loading functionality  \n3. **Model Architecture** - Leverage pre-built transformer models\n4. **Pre-trained Model Loading** - Load and configure saved models\n5. **Mid-Rally Prediction Testing** - Test on real tennis sequences\n6. **Interactive Prediction** - Make predictions on custom rally strings\n7. **Performance Analysis** - Comprehensive model evaluation\n8. **Tactical Intelligence** - Analyze tennis-specific AI capabilities\n\n---","metadata":{}},{"id":"18d9bb9b-4a28-4cb5-bfed-0766956a6c8d","cell_type":"code","source":"import sys\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"GITHUB_TOKEN\")\nsecret_value_1 = user_secrets.get_secret(\"GITHUB_USER\")\n\n!cd \"/kaggle/working/\"\n!rm -r \"/kaggle/working/Tennis-Shot-Prediction\"\n\n!git clone https://{secret_value_1}:{secret_value_0}@github.com/SoykatAmin/Tennis-Shot-Prediction.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"be61bc8f-1975-48d4-9c21-ce77cb722e1d","cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/Tennis-Shot-Prediction/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2f513fef","cell_type":"markdown","source":"## 1. Setup and Environment Configuration\n\nLet's start by importing the necessary libraries and setting up our environment. We'll use the modular structure from our repository.","metadata":{}},{"id":"0c38dd32","cell_type":"code","source":"# Core libraries\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport os\nimport sys\nfrom pathlib import Path\n\n# Add the src directory to the path so we can import our modules\nrepo_root = Path.cwd().parent  # Go up from notebooks to repo root\nsys.path.append(str(repo_root))\nprint(f\"Repository root: {repo_root}\")\n\n# Import our custom modules from the repository\nfrom src.data import MCPTennisDataset, create_data_loaders, compute_class_weights\nfrom src.data.utils import (\n    calculate_directional_accuracy, \n    calculate_winner_detection_rate,\n    calculate_top_k_accuracy\n)\nfrom src.models import SymbolicTinyRM_PlayerAware, SymbolicTinyRM_Context, FocalLoss\nfrom src.utils import setup_logging, get_device, print_model_summary\n\nprint(\"‚úÖ All imports successful!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d39a51ae","cell_type":"code","source":"# Configuration\nDEVICE = get_device('auto')  # Use our utility function\nSEQ_LEN = 30\nBATCH_SIZE = 64\nEPOCHS = 10\n\nprint(f\"Using device: {DEVICE}\")\nprint(f\"Sequence length: {SEQ_LEN}\")\nprint(f\"Batch size: {BATCH_SIZE}\")\n\n# Data paths - Update these to match your system\n# For demo purposes, we'll use sample paths\nDATA_PATHS = {\n    'atp_points': '/kaggle/input/tennis-match-charting-project/charting-m-points.csv',\n    'atp_matches': '/kaggle/input/tennis-match-charting-project/charting-m-matches.csv', \n    'atp_players': '/kaggle/input/tennis-players/atp_players.csv',\n    'wta_players': '/kaggle/input/tennis-players/wta_players.csv',\n    'points_path': '/kaggle/input/tennis-match-charting-project/charting-m-points.csv',\n    'matches_path': '/kaggle/input/tennis-match-charting-project/charting-m-matches.csv'\n}\n\n# Check if data files exist\nfor name, path in DATA_PATHS.items():\n    full_path = repo_root / path\n    exists = full_path.exists()\n    print(f\"üìÅ {name}: {'‚úÖ Found' if exists else '‚ùå Not found'} at {full_path}\")\n\nprint(\"\\nüí° Note: Update DATA_PATHS above with your actual file locations if files not found.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b18c1075","cell_type":"markdown","source":"## 2. Load and Initialize Dataset\n\nNow we'll use the repository's `MCPTennisDataset` class to load and process tennis data. This class handles all the complex data preprocessing, including:\n- Rally sequence parsing\n- Player handedness information\n- Data augmentation (left/right mirroring)\n- Context encoding (surface, score, etc.)","metadata":{}},{"id":"915ce562","cell_type":"code","source":"dataset = MCPTennisDataset(DATA_PATHS['points_path'], DATA_PATHS['matches_path'], DATA_PATHS['atp_players'], DATA_PATHS['wta_players'], max_seq_len=SEQ_LEN)\n\n# Display dataset information\nprint(f\"\\nüìä Dataset Information:\")\nprint(f\"Total samples: {len(dataset):,}\")\nprint(f\"Shot vocabulary size: {len(dataset.shot_vocab)}\")\nprint(f\"Zone vocabulary size: {len(dataset.zone_vocab)}\")\nprint(f\"Player vocabulary size: {len(dataset.player_vocab)}\")\nprint(f\"Surface types: {list(dataset.surface_vocab.keys())}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"469c54f8","cell_type":"markdown","source":"## 3. Define Model Architecture\n\nThe repository provides two main model architectures:\n1. **`SymbolicTinyRM_PlayerAware`** - Includes player embeddings for personalized predictions\n2. **`SymbolicTinyRM_Context`** - Context-only model without player-specific information\n\nLet's initialize both models to see their capabilities.","metadata":{}},{"id":"69849326","cell_type":"code","source":"# Model configuration\nMODEL_CONFIG = {\n    'embed_dim': 64,\n    'n_head': 4,\n    'n_cycles': 3,\n    'seq_len': SEQ_LEN,\n    'context_dim': 6,\n    'dropout': 0.1\n}\n\nprint(\"ü§ñ Initializing Models...\")\n\n# 1. Player-aware model (includes player embeddings)\nplayer_aware_model = SymbolicTinyRM_PlayerAware(\n    zone_vocab_size=len(dataset.zone_vocab),\n    type_vocab_size=len(dataset.shot_vocab),\n    num_players=len(dataset.player_vocab),\n    **MODEL_CONFIG\n).to(DEVICE)\n\nprint(\"‚úÖ Player-aware model created\")\nprint_model_summary(player_aware_model, \"Player-Aware Transformer\")\n\n# 2. Context-only model (no player embeddings)\ncontext_model = SymbolicTinyRM_Context(\n    zone_vocab_size=len(dataset.zone_vocab),\n    type_vocab_size=len(dataset.shot_vocab),\n    **MODEL_CONFIG\n).to(DEVICE)\n\nprint(\"‚úÖ Context-only model created\")\nprint_model_summary(context_model, \"Context-Only Transformer\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"505c5420","cell_type":"markdown","source":"## 4. Load Pre-trained Model Weights\n\nIn a real scenario, you would load pre-trained weights here. For this demo, we'll show how the loading process would work and then train a small model for demonstration.","metadata":{}},{"id":"8c7357c3","cell_type":"code","source":"# Check for pre-trained models in checkpoints directory\ncheckpoint_dir = repo_root / 'checkpoints'\ncheckpoint_dir.mkdir(exist_ok=True)\n\n# Look for saved models\nmodel_files = list(checkpoint_dir.glob('*.pth'))\nprint(f\"üîç Found {len(model_files)} model files in {checkpoint_dir}\")\n\n# User choice: Load weights or train model\nprint(\"\\nüéØ MODEL INITIALIZATION OPTIONS:\")\nprint(\"1. Load pre-trained weights (if available)\")\nprint(\"2. Train model from scratch\")\nprint(\"3. Use randomly initialized model (for quick demo)\")\n\n# For interactive use, you can change this variable\nUSER_CHOICE = 2  # Change this to 1, 2, or 3 based on your preference\n\nmodel_loaded = False\n\nif USER_CHOICE == 1 and model_files:\n    print(f\"\\nüìÇ Available models:\")\n    for i, model_file in enumerate(model_files):\n        print(f\"  {i+1}. {model_file.name}\")\n    \n    # Try to load the first model found (you can modify this to select a specific model)\n    try:\n        model_path = model_files[0]  # Use first model, or change index to select different model\n        print(f\"\\nüîÑ Loading model from {model_path}\")\n        \n        # Load the state dict\n        checkpoint = torch.load(model_path, map_location=DEVICE)\n        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n            player_aware_model.load_state_dict(checkpoint['model_state_dict'])\n            print(f\"‚úÖ Loaded player-aware model state from checkpoint\")\n            if 'context_model_state_dict' in checkpoint:\n                context_model.load_state_dict(checkpoint['context_model_state_dict'])\n                print(f\"‚úÖ Loaded context-only model state from checkpoint\")\n        else:\n            player_aware_model.load_state_dict(checkpoint)\n            print(f\"‚úÖ Loaded player-aware model state directly\")\n        \n        model_loaded = True\n            \n    except Exception as e:\n        print(f\"‚ö†Ô∏è Could not load model: {e}\")\n        print(\"Will train model from scratch instead...\")\n        USER_CHOICE = 2\n\nelif USER_CHOICE == 2:\n    print(\"\\nüéì TRAINING MODELS FROM SCRATCH\")\n    print(\"This will train both models for a few epochs...\")\n    \n    # Quick training function\n    # Quick training function\n    def quick_train_models(player_model, context_model, dataset, epochs=EPOCHS):\n        from torch.utils.data import DataLoader, random_split\n        from src.models import FocalLoss\n        import torch\n        \n        # Split dataset into train (80%) and validation (20%)\n        train_size = int(0.8 * len(dataset))\n        val_size = len(dataset) - train_size\n        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n        \n        print(f\"üìä Dataset split: {train_size} training, {val_size} validation samples\")\n        \n        # Create data loaders\n        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n        \n        # Loss function and optimizers\n        # FIX: Changed alpha=1.0 to alpha=None to avoid 'float' object error\n        criterion = FocalLoss(alpha=None, gamma=2.0, reduction='mean')\n        \n        optimizer_pa = torch.optim.AdamW(player_model.parameters(), lr=1e-3, weight_decay=1e-4)\n        optimizer_co = torch.optim.AdamW(context_model.parameters(), lr=1e-3, weight_decay=1e-4)\n        \n        print(f\"üèÉ Training for {epochs} epochs with train/validation split...\")\n        \n        for epoch in range(epochs):\n            # --- Training phase ---\n            player_model.train()\n            context_model.train()\n            \n            # FIX: Initialize variables with the names used inside the loop\n            total_loss_pa = 0\n            total_loss_co = 0\n            num_batches = 0\n            \n            print(f\"\\nüìà Epoch {epoch+1}/{epochs} - Training...\")\n            for batch_idx, batch in enumerate(train_loader):\n                if batch_idx >= 15:  # Limit to 15 batches per epoch for quick training\n                    break\n                \n                try:\n                    # Handle context\n                    if isinstance(batch['context'], (list, tuple)):\n                        x_context = torch.stack([torch.tensor(ctx, dtype=torch.float32) for ctx in batch['context']]).to(DEVICE)\n                    elif isinstance(batch['context'], torch.Tensor):\n                        x_context = batch['context'].to(DEVICE)\n                    else:\n                        x_context = torch.tensor(batch['context'], dtype=torch.float32).to(DEVICE)\n                        if x_context.dim() == 1:\n                            x_context = x_context.unsqueeze(0)\n                    \n                    x_zone = batch['x_zone'].to(DEVICE)\n                    x_type = batch['x_type'].to(DEVICE) \n                    y_target = batch['y_target'].to(DEVICE)\n                    \n                    batch_size = x_zone.size(0)\n                    \n                    # --- 1. Train Player-Aware Model ---\n                    optimizer_pa.zero_grad()\n                    \n                    # Handle player IDs\n                    if 'x_s_id' in batch and 'x_r_id' in batch:\n                        x_s_id = batch['x_s_id'].to(DEVICE)\n                        x_r_id = batch['x_r_id'].to(DEVICE)\n                    else:\n                        # Dummy IDs if missing\n                        x_s_id = torch.zeros(batch_size, dtype=torch.long, device=DEVICE)\n                        x_r_id = torch.zeros(batch_size, dtype=torch.long, device=DEVICE)\n                \n                    logits_pa = player_model(x_zone, x_type, x_context, x_s_id, x_r_id)\n                    loss_pa = criterion(logits_pa.view(-1, logits_pa.size(-1)), y_target.view(-1))\n                    loss_pa.backward()\n                    optimizer_pa.step()\n                    \n                    # --- 2. Train Context-Only Model ---\n                    optimizer_co.zero_grad()\n                    logits_co = context_model(x_zone, x_type, x_context)\n                    loss_co = criterion(logits_co.view(-1, logits_co.size(-1)), y_target.view(-1))\n                    loss_co.backward()\n                    optimizer_co.step()\n                    \n                    # Update totals\n                    total_loss_pa += loss_pa.item()\n                    total_loss_co += loss_co.item()\n                    num_batches += 1\n                \n                except Exception as batch_error:\n                    print(f\"   Skipping batch {batch_idx} due to error: {batch_error}\")\n                    continue\n            \n            # Calculate training averages\n            avg_train_loss_pa = total_loss_pa / num_batches if num_batches > 0 else 0\n            avg_train_loss_co = total_loss_co / num_batches if num_batches > 0 else 0\n            \n            # --- Validation phase ---\n            print(f\"üìä Epoch {epoch+1}/{epochs} - Validation...\")\n            player_model.eval()\n            context_model.eval()\n            \n            val_loss_pa = 0\n            val_loss_co = 0\n            val_correct_pa = 0\n            val_correct_co = 0\n            val_total = 0\n            val_batches = 0\n            \n            with torch.no_grad():\n                for batch_idx, batch in enumerate(val_loader):\n                    if batch_idx >= 5:  # Limit validation batches\n                        break\n                    \n                    try:\n                        # Handle validation batch data\n                        if isinstance(batch['context'], (list, tuple)):\n                            x_context = torch.stack([torch.tensor(ctx, dtype=torch.float32) for ctx in batch['context']]).to(DEVICE)\n                        elif isinstance(batch['context'], torch.Tensor):\n                            x_context = batch['context'].to(DEVICE)\n                        else:\n                            x_context = torch.tensor(batch['context'], dtype=torch.float32).to(DEVICE)\n                            if x_context.dim() == 1:\n                                x_context = x_context.unsqueeze(0)\n                        \n                        x_zone = batch['x_zone'].to(DEVICE)\n                        x_type = batch['x_type'].to(DEVICE) \n                        y_target = batch['y_target'].to(DEVICE)\n                        batch_size = x_zone.size(0)\n                        \n                        # Handle player IDs\n                        if 'x_s_id' in batch and 'x_r_id' in batch:\n                            x_s_id = batch['x_s_id'].to(DEVICE)\n                            x_r_id = batch['x_r_id'].to(DEVICE)\n                        else:\n                            x_s_id = torch.zeros(batch_size, dtype=torch.long, device=DEVICE)\n                            x_r_id = torch.zeros(batch_size, dtype=torch.long, device=DEVICE)\n                        \n                        # Forward pass\n                        logits_pa = player_model(x_zone, x_type, x_context, x_s_id, x_r_id)\n                        logits_co = context_model(x_zone, x_type, x_context)\n                        \n                        # Loss\n                        loss_pa = criterion(logits_pa.view(-1, logits_pa.size(-1)), y_target.view(-1))\n                        loss_co = criterion(logits_co.view(-1, logits_co.size(-1)), y_target.view(-1))\n                        \n                        val_loss_pa += loss_pa.item()\n                        val_loss_co += loss_co.item()\n                        \n                        # Accuracy (mask padding)\n                        mask = (y_target != 0)\n                        if mask.any():\n                            pred_pa = logits_pa.argmax(dim=-1)\n                            pred_co = logits_co.argmax(dim=-1)\n                            \n                            val_correct_pa += (pred_pa[mask] == y_target[mask]).sum().item()\n                            val_correct_co += (pred_co[mask] == y_target[mask]).sum().item()\n                            val_total += mask.sum().item()\n                        \n                        val_batches += 1\n                        \n                    except Exception as val_error:\n                        continue\n            \n            # Calculate validation averages\n            avg_val_loss_pa = val_loss_pa / val_batches if val_batches > 0 else 0\n            avg_val_loss_co = val_loss_co / val_batches if val_batches > 0 else 0\n            val_acc_pa = val_correct_pa / val_total if val_total > 0 else 0\n            val_acc_co = val_correct_co / val_total if val_total > 0 else 0\n            \n            # Print epoch results\n            print(f\"‚úÖ Epoch {epoch+1}/{epochs} Results:\")\n            print(f\"   Train Loss - PA: {avg_train_loss_pa:.4f}, CO: {avg_train_loss_co:.4f}\")\n            print(f\"   Val Loss   - PA: {avg_val_loss_pa:.4f}, CO: {avg_val_loss_co:.4f}\")\n            print(f\"   Val Acc    - PA: {val_acc_pa*100:.2f}%, CO: {val_acc_co*100:.2f}%\")\n        \n        # Save models\n        checkpoint_path = checkpoint_dir / 'quick_trained_model.pth'\n        torch.save({\n            'model_state_dict': player_model.state_dict(),\n            'context_model_state_dict': context_model.state_dict(),\n            'epoch': epochs,\n            'training_type': 'quick_demo'\n        }, checkpoint_path)\n        \n        print(f\"‚úÖ Quick training completed! Models saved to {checkpoint_path}\")\n        return True\n    \n    try:\n        model_loaded = quick_train_models(player_aware_model, context_model, dataset)\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Training failed: {e}\")\n        print(\"Will use randomly initialized models...\")\n        USER_CHOICE = 3\n\nif not model_loaded or USER_CHOICE == 3:\n    print(\"\\nüé≤ Using randomly initialized models for demonstration\")\n    print(\"   Note: Performance will be random since models are not trained\")\n    print(\"   To get meaningful results:\")\n    print(\"   1. Set USER_CHOICE = 2 to train models\")\n    print(\"   2. Or provide pre-trained weights and set USER_CHOICE = 1\")\n\n# Set models to evaluation mode\nplayer_aware_model.eval()\ncontext_model.eval()\nprint(f\"\\n‚úÖ Models ready for inference!\")\n\nprint(f\"\\nüìã Current Setup:\")\nprint(f\"   Choice: {['', 'Load pre-trained weights', 'Train from scratch', 'Random initialization'][USER_CHOICE]}\")\nprint(f\"   Model loaded: {'Yes' if model_loaded else 'No'}\")\nprint(f\"   Ready for predictions: Yes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7ea7e389","cell_type":"markdown","source":"## 5. Mid-Rally Prediction Testing\n\nLet's test the model's ability to predict shots in the middle of rallies. This demonstrates the core functionality of the tennis shot prediction system.","metadata":{}},{"id":"248d7c92","cell_type":"code","source":"def test_mid_rally_prediction(model, dataset, num_samples=5, model_type='player_aware'):\n    \"\"\"\n    Test the model on partial rally sequences.\n    \n    Args:\n        model: The neural network model\n        dataset: Tennis dataset\n        num_samples: Number of samples to test\n        model_type: 'player_aware' or 'context_only'\n    \"\"\"\n    print(f\"üéæ Testing {model_type} model on {num_samples} mid-rally predictions...\\n\")\n    \n    # Create reverse vocabularies\n    idx_to_zone = {v: k for k, v in dataset.zone_vocab.items()}\n    idx_to_shot = {v: k for k, v in dataset.shot_vocab.items()}\n    \n    model.eval()\n    correct_predictions = 0\n    \n    # Randomly select samples for testing\n    test_indices = np.random.choice(len(dataset), num_samples, replace=False)\n    \n    with torch.no_grad():\n        for i, idx in enumerate(test_indices):\n            sample = dataset[idx]\n            \n            # Find non-padding positions\n            valid_positions = (sample['x_zone'] != 0).nonzero(as_tuple=True)[0]\n            \n            if len(valid_positions) < 3:  # Need at least 3 shots for meaningful test\n                continue\n                \n            # Test prediction at the last position\n            test_pos = valid_positions[-1].item()\n            true_target = sample['y_target'][test_pos].item()\n            \n            if true_target == 0:  # Skip if target is padding\n                continue\n            \n            # Prepare input tensors\n            x_zone = sample['x_zone'].unsqueeze(0).to(DEVICE)\n            x_type = sample['x_type'].unsqueeze(0).to(DEVICE)\n            x_context = sample['context'].unsqueeze(0).to(DEVICE)\n            \n            # Make prediction based on model type\n            if model_type == 'player_aware':\n                x_s_id = sample['x_s_id'].unsqueeze(0).to(DEVICE)\n                x_r_id = sample['x_r_id'].unsqueeze(0).to(DEVICE)\n                logits = model(x_zone, x_type, x_context, x_s_id, x_r_id)\n            else:\n                logits = model(x_zone, x_type, x_context)\n            \n            # Get prediction at test position\n            pred_logits = logits[0, test_pos]\n            pred_zone_idx = pred_logits.argmax().item()\n            \n            # Get top 3 predictions\n            top_probs, top_indices = torch.topk(torch.softmax(pred_logits, dim=0), 3)\n            \n            # Convert to readable format\n            pred_zone = idx_to_zone.get(pred_zone_idx, '?')\n            true_zone = idx_to_zone.get(true_target, '?')\n            \n            # Build rally history for display\n            rally_parts = []\n            for j in valid_positions[:test_pos]:\n                zone = idx_to_zone.get(sample['x_zone'][j].item(), '?')\n                shot = idx_to_shot.get(sample['x_type'][j].item(), '?')\n                rally_parts.append(f\"{zone}{shot}\")\n            \n            rally_str = \" \".join(rally_parts)\n            \n            # Check if prediction is correct\n            is_correct = (pred_zone == true_zone)\n            if is_correct:\n                correct_predictions += 1\n            \n            # Display results\n            status_emoji = \"‚úÖ\" if is_correct else \"‚ùå\"\n            print(f\"{status_emoji} Sample {i+1}:\")\n            print(f\"   Rally: {rally_str} ‚Üí ?\")\n            print(f\"   Predicted: Zone {pred_zone} | Actual: Zone {true_zone}\")\n            print(f\"   Top 3 predictions:\")\n            \n            for k, (prob, zone_idx) in enumerate(zip(top_probs, top_indices)):\n                zone = idx_to_zone.get(zone_idx.item(), '?')\n                if zone != '<pad>':\n                    print(f\"      {k+1}. Zone {zone}: {prob.item()*100:.1f}%\")\n            \n            print()\n    \n    accuracy = correct_predictions / num_samples if num_samples > 0 else 0\n    print(f\"üìä Accuracy: {correct_predictions}/{num_samples} ({accuracy*100:.1f}%)\")\n    return accuracy\n\n# Test both models\nprint(\"=\" * 60)\naccuracy_player = test_mid_rally_prediction(player_aware_model, dataset, 5, 'player_aware')\nprint(\"\\n\" + \"=\" * 60)\naccuracy_context = test_mid_rally_prediction(context_model, dataset, 5, 'context_only')\n\nprint(f\"\\nüèÜ Results Summary:\")\nprint(f\"   Player-aware model accuracy: {accuracy_player*100:.1f}%\")\nprint(f\"   Context-only model accuracy: {accuracy_context*100:.1f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"61c5a42b","cell_type":"markdown","source":"## 6. Interactive Shot Prediction\n\nLet's create an interactive interface to make predictions based on custom rally sequences.","metadata":{}},{"id":"ed62adf6","cell_type":"code","source":"def predict_next_shot(rally_sequence, model, dataset, model_type='player_aware'):\n    \"\"\"\n    Predict the next shot given a rally sequence.\n    \n    Args:\n        rally_sequence: List of tuples like [('1', 'b'), ('8', 'f'), ...]\n        model: The neural network model\n        dataset: Tennis dataset\n        model_type: 'player_aware' or 'context_only'\n    \n    Returns:\n        Dictionary with prediction results\n    \"\"\"\n    print(f\"üîÆ Predicting next shot with {model_type} model...\")\n    print(f\"Rally: {' ‚Üí '.join([f'Zone{z}{t}' for z, t in rally_sequence])}\")\n    \n    # Create reverse vocabularies\n    idx_to_zone = {v: k for k, v in dataset.zone_vocab.items()}\n    \n    # Convert rally to tensor format - use SEQ_LEN to match model expectations\n    max_seq_len = SEQ_LEN  # Use the same sequence length as the model was initialized with\n    zones = [0] * max_seq_len\n    shot_types = [0] * max_seq_len\n    \n    for i, (zone, shot_type) in enumerate(rally_sequence[:max_seq_len]):\n        zones[i] = dataset.zone_vocab.get(zone, 0)\n        shot_types[i] = dataset.shot_vocab.get(shot_type, 0)\n    \n    # Create tensors\n    x_zone = torch.tensor(zones, dtype=torch.long).unsqueeze(0).to(DEVICE)\n    x_type = torch.tensor(shot_types, dtype=torch.long).unsqueeze(0).to(DEVICE)\n    \n    # Create dummy context (for mock data) - match the context_dim from model config\n    # Context format: [surface, server_score, receiver_score, is_second_serve, server_hand, receiver_hand]\n    dummy_context = [1.0, 0.0, 0.0, 0.0, 1.0, 1.0]  # 6 features\n    x_context = torch.tensor(dummy_context, dtype=torch.float).unsqueeze(0).to(DEVICE)  # [1, 6]\n    \n    model.eval()\n    with torch.no_grad():\n        # Make prediction based on model type\n        if model_type == 'player_aware':\n            # Use dummy player IDs for mock prediction\n            x_s_id = torch.tensor([2], dtype=torch.long).to(DEVICE)  # Single server ID\n            x_r_id = torch.tensor([3], dtype=torch.long).to(DEVICE)  # Single receiver ID\n            logits = model(x_zone, x_type, x_context, x_s_id, x_r_id)\n        else:\n            logits = model(x_zone, x_type, x_context)\n        \n        # Get prediction at the next position\n        pred_pos = len(rally_sequence)\n        if pred_pos < max_seq_len:\n            pred_logits = logits[0, pred_pos]\n            probs = torch.softmax(pred_logits, dim=0)\n            \n            # Get top 5 predictions\n            top_probs, top_indices = torch.topk(probs, min(5, len(dataset.zone_vocab)))\n            \n            predictions = []\n            for prob, zone_idx in zip(top_probs, top_indices):\n                zone = idx_to_zone.get(zone_idx.item(), '?')\n                if zone != '<pad>':\n                    predictions.append({\n                        'zone': zone,\n                        'probability': prob.item(),\n                        'confidence': 'High' if prob.item() > 0.3 else 'Medium' if prob.item() > 0.15 else 'Low'\n                    })\n            \n            return predictions\n        else:\n            print(\"Rally sequence is too long!\")\n            return []\n\n# Example rally sequences to test\nexample_rallies = [\n    [('4', 'b'), ('6', 'f')],  # Backhand to zone 4, forehand to zone 6\n    [('1', 'b'), ('8', 'f'), ('3', 'b')],  # Longer rally\n    [('2', 'v'), ('7', 'f')],  # Volley followed by forehand\n    [('5', 'f'), ('5', 'b'), ('6', 'f')]  # Back and forth rally\n]\n\nprint(\"üéæ Interactive Shot Prediction Examples\\n\")\nprint(\"=\" * 70)\n\n# Test with both models\nfor i, rally in enumerate(example_rallies[:2]):  # Test first 2 examples\n    print(f\"\\nüìã Example {i+1}:\")\n    print(\"-\" * 30)\n    \n    # Player-aware model prediction\n    predictions_pa = predict_next_shot(rally, player_aware_model, dataset, 'player_aware')\n    print(\"\\nü§ñ Player-aware model predictions:\")\n    if not predictions_pa:\n        print(\"   No predictions\")\n    else:\n        for j, pred in enumerate(predictions_pa[:3]):\n            print(f\"   {j+1}. Zone {pred['zone']}: {pred['probability']*100:.1f}% ({pred['confidence']})\")\n    \n    # Context-only model prediction\n    predictions_co = predict_next_shot(rally, context_model, dataset, 'context_only')\n    print(\"\\nüß† Context-only model predictions:\")\n    if not predictions_co:\n        print(\"   No predictions\")\n    else:\n        for j, pred in enumerate(predictions_co[:3]):\n            print(f\"   {j+1}. Zone {pred['zone']}: {pred['probability']*100:.1f}% ({pred['confidence']})\")\n    \n    print(\"\\n\" + \"=\" * 70)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0a4ac9af","cell_type":"markdown","source":"## 7. Performance Analysis\n\nLet's analyze the models' performance and compare their capabilities.","metadata":{}},{"id":"638cd798","cell_type":"code","source":"def analyze_model_performance(model, dataset, model_type, num_samples=50):\n    \"\"\"\n    Comprehensive performance analysis of a model.\n    \n    Args:\n        model: The neural network model\n        dataset: Tennis dataset\n        model_type: 'player_aware' or 'context_only'\n        num_samples: Number of samples to analyze\n    \n    Returns:\n        Dictionary with performance metrics\n    \"\"\"\n    print(f\"üìä Analyzing {model_type} model performance on {num_samples} samples...\")\n    \n    model.eval()\n    correct_predictions = 0\n    total_predictions = 0\n    confidence_scores = []\n    prediction_probabilities = []\n    \n    # Create reverse vocabularies\n    idx_to_zone = {v: k for k, v in dataset.zone_vocab.items()}\n    \n    with torch.no_grad():\n        test_indices = np.random.choice(len(dataset), num_samples, replace=False)\n        \n        for idx in test_indices:\n            sample = dataset[idx]\n            \n            # Find valid positions\n            valid_positions = (sample['x_zone'] != 0).nonzero(as_tuple=True)[0]\n            \n            if len(valid_positions) < 2:\n                continue\n            \n            # Test multiple positions in each rally\n            for pos in valid_positions[1:]:  # Skip first position\n                true_target = sample['y_target'][pos].item()\n                if true_target == 0:  # Skip padding\n                    continue\n                \n                # Prepare input\n                x_zone = sample['x_zone'].unsqueeze(0).to(DEVICE)\n                x_type = sample['x_type'].unsqueeze(0).to(DEVICE)\n                x_context = sample['context'].unsqueeze(0).to(DEVICE)\n                \n                # Make prediction\n                if model_type == 'player_aware':\n                    x_s_id = sample['x_s_id'].unsqueeze(0).to(DEVICE)\n                    x_r_id = sample['x_r_id'].unsqueeze(0).to(DEVICE)\n                    logits = model(x_zone, x_type, x_context, x_s_id, x_r_id)\n                else:\n                    logits = model(x_zone, x_type, x_context)\n                \n                # Calculate metrics\n                pred_logits = logits[0, pos]\n                probs = torch.softmax(pred_logits, dim=0)\n                pred_idx = pred_logits.argmax().item()\n                \n                # Store results\n                total_predictions += 1\n                if pred_idx == true_target:\n                    correct_predictions += 1\n                \n                max_prob = probs.max().item()\n                confidence_scores.append(max_prob)\n                prediction_probabilities.append(probs.cpu().numpy())\n    \n    # Calculate metrics\n    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n    avg_confidence = np.mean(confidence_scores) if confidence_scores else 0\n    confidence_std = np.std(confidence_scores) if confidence_scores else 0\n    \n    results = {\n        'accuracy': accuracy,\n        'total_predictions': total_predictions,\n        'correct_predictions': correct_predictions,\n        'average_confidence': avg_confidence,\n        'confidence_std': confidence_std,\n        'model_type': model_type\n    }\n    \n    # Display results\n    print(f\"\\nüìà {model_type.title()} Model Results:\")\n    print(f\"   Accuracy: {accuracy*100:.2f}% ({correct_predictions}/{total_predictions})\")\n    print(f\"   Average Confidence: {avg_confidence*100:.2f}% (¬±{confidence_std*100:.2f}%)\\n\")\n\n    return results\n\n# Analyze both models\nprint(\"=\" * 80)\nresults_player = analyze_model_performance(player_aware_model, dataset, 'player_aware', 30)\nprint(\"\\n\" + \"=\" * 80)\nresults_context = analyze_model_performance(context_model, dataset, 'context_only', 30)\n\n# Compare models\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üèÜ MODEL COMPARISON\")\nprint(\"=\" * 80)\nprint(\"üìä Accuracy Comparison:\")\nprint(f\"   Player-aware: {results_player['accuracy']*100:.2f}%\")\nprint(f\"   Context-only: {results_context['accuracy']*100:.2f}%\")\nprint(f\"   Difference: {(results_player['accuracy'] - results_context['accuracy'])*100:.2f}%\")\n\nprint(f\"\\nüéØ Confidence Comparison:\")\nprint(f\"   Player-aware: {results_player['average_confidence']*100:.2f}%\")\nprint(f\"   Context-only: {results_context['average_confidence']*100:.2f}%\")\n\n# Determine better model\nbetter_model = \"Player-aware\" if results_player['accuracy'] > results_context['accuracy'] else \"Context-only\"\nprint(f\"\\nü•á Better performing model: {better_model}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9a0639a","cell_type":"markdown","source":"## 8. Tactical Intelligence Analysis\n\nLet's explore what tactical patterns our models have learned.","metadata":{}},{"id":"fef64124","cell_type":"code","source":"def analyze_tactical_patterns(model, dataset, model_type):\n    \"\"\"\n    Analyze tactical patterns learned by the model.\n    \"\"\"\n    print(f\"üéØ Analyzing tactical patterns in {model_type} model...\")\n    \n    # Define common tactical scenarios\n    tactical_scenarios = {\n        \"Cross-court rallies\": [(\"1\", \"b\"), (\"8\", \"f\")],\n        \"Down-the-line pressure\": [(\"1\", \"f\"), (\"1\", \"b\")],\n        \"Serve and volley\": [(\"4\", \"s\"), (\"2\", \"v\")],\n        \"Defensive lob\": [(\"8\", \"f\"), (\"3\", \"l\")],\n        \"Approach shot\": [(\"5\", \"f\"), (\"2\", \"v\")]\n    }\n    \n    print(\"\\nüß† Tactical Pattern Analysis:\")\n    print(\"=\" * 50)\n    \n    for scenario_name, rally in tactical_scenarios.items():\n        print(f\"\\nüìã {scenario_name}:\")\n        print(f\"   Setup: {' ‚Üí '.join([f'Zone{z}{t.upper()}' for z, t in rally])}\")\n        \n        predictions = predict_next_shot(rally, model, dataset, model_type)\n        \n        if predictions:\n            top_pred = predictions[0]\n            print(f\"   üí° Model suggests: Zone {top_pred['zone']} ({top_pred['probability']*100:.1f}% confidence)\")\n            \n            # Tactical interpretation\n            tactical_meaning = interpret_tactical_choice(rally[-1], top_pred['zone'])\n            print(f\"   üéæ Tactical insight: {tactical_meaning}\")\n        else:\n            print(\"   ‚ùå No valid predictions\")\n    \n    return None\ndef interpret_tactical_choice(last_shot, predicted_zone):\n    \"\"\"Provide tactical interpretation of predicted shot.\"\"\"\n    last_zone, last_type = last_shot\n    \n    # Simple tactical interpretation logic\n    if predicted_zone in ['1', '2', '3']:\n        if last_zone in ['6', '7', '8']:\n            return \"Cross-court shot to change direction\"\n        else:\n            return \"Down-the-line shot to maintain pressure\"\n    elif predicted_zone in ['6', '7', '8']:\n        if last_zone in ['1', '2', '3']:\n            return \"Cross-court shot to open the court\"\n        else:\n            return \"Same-side shot to maintain rally\"\n    elif predicted_zone in ['4', '5']:\n        return \"Central shot to maintain neutral position\"\n    else:\n        return \"Defensive positioning\"\n# Analyze both models' tactical understanding\nprint(\"üéæ TACTICAL INTELLIGENCE COMPARISON\")\nprint(\"=\" * 80)\n\nprint(\"\\nü§ñ PLAYER-AWARE MODEL:\")\nanalyze_tactical_patterns(player_aware_model, dataset, 'player_aware')\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"\\nüß† CONTEXT-ONLY MODEL:\")\nanalyze_tactical_patterns(context_model, dataset, 'context_only')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}